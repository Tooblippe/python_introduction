{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Classification \n",
    "\n",
    "(Still some issues with this notebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from ggplot import *\n",
    "\n",
    "# Enable inline plotting\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "# The data has some meta data appended at the top of the file\n",
    "# The data is stored in the array \"data\"\n",
    "# The field names are stored in \"feature_names\"\n",
    "# Acutal flower names are stored in \"target\"\n",
    "col_names = data['feature_names']\n",
    "\n",
    "df = pd.DataFrame(data['data'], columns = col_names)\n",
    "# Add in the Iris Id data\n",
    "df['Iris Flower'] = data['target']\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly re-name the **Iris flower** from an integer to the actual names as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Iris Flower'][df['Iris Flower']== 0] = 'Setosa' \n",
    "df['Iris Flower'][df['Iris Flower']== 1] = 'Versicolor' \n",
    "df['Iris Flower'][df['Iris Flower']== 2] = 'Virginica' \n",
    "# Print unique names to test if it worked properly\n",
    "print pd.unique(df[\"Iris Flower\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a quick look at our data so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always a good idea to start plotting early to get a deeper sense of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(df, figsize=[12,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks alright, but really we want to see the different flowers as separate colors, which is not easily possible right now. I did however find a keen <a href = \"\"http://stackoverflow.com/users/1586229/bgschiller>\"Stack Overflow user</a> who developed a custom version for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def factor_scatter_matrix(df, factor, palette=None):\n",
    "\n",
    "    import matplotlib.colors\n",
    "    from scipy.stats import gaussian_kde\n",
    "\n",
    "    if isinstance(factor, basestring):\n",
    "        factor_name = factor #save off the name\n",
    "        factor = df[factor] #extract column\n",
    "        df = df.drop(factor_name,axis=1) # remove from df, so it \n",
    "        # doesn't get a row and col in the plot.\n",
    "\n",
    "    classes = list(set(factor))\n",
    "\n",
    "    if palette is None:\n",
    "        palette = ['#e41a1c', '#377eb8', '#4eae4b', \n",
    "                   '#994fa1', '#ff8101', '#fdfc33', \n",
    "                   '#a8572c', '#f482be', '#999999']\n",
    "\n",
    "    color_map = dict(zip(classes,palette))\n",
    "\n",
    "    if len(classes) > len(palette):\n",
    "        raise ValueError('''Too many groups for the number of colors provided.\n",
    "We only have {} colors in the palette, but you have {}\n",
    "groups.'''.format(len(palette), len(classes)))\n",
    "\n",
    "    colors = factor.apply(lambda group: color_map[group])\n",
    "    axarr = scatter_matrix(df,figsize=(10,10),marker='o',c=colors,diagonal=None)\n",
    "\n",
    "\n",
    "    for rc in xrange(len(df.columns)):\n",
    "        for group in classes:\n",
    "            y = df[factor == group].icol(rc).values\n",
    "            gkde = gaussian_kde(y)\n",
    "            ind = np.linspace(y.min(), y.max(), 1000)\n",
    "            axarr[rc][rc].plot(ind, gkde.evaluate(ind),c=color_map[group])\n",
    "\n",
    "    return axarr, color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "axarr, color_map = factor_scatter_matrix(df,'Iris Flower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ITS BEAUTIFUL**\n",
    "\n",
    "On the subject of useful plotting methods, <a href = \"http://stanford.edu/~mwaskom/software/seaborn/tutorial/axis_grids.html#plotting-bivariate-data-with-jointgrid\"> Seaborn</a> is producing some really cool stuff. I find the scatterplot + histograms really useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyways, ggplot can at least take care of the rest of out plotting needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(ggplot(df, aes(x=\"petal length (cm)\",y=\"petal width (cm)\", color = \"Iris Flower\"))+geom_point())\n",
    "print(ggplot(df, aes(x=\"sepal length (cm)\",y=\"sepal width (cm)\", color = \"Iris Flower\"))+geom_point())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The simplest way to classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to develop a model to classify the three different types of flowers. \n",
    "\n",
    "By inspecting the graphs above, we can see that there is actually a very clear separation in petal length and width between Iris Setosa and the other two flowers. \n",
    "\n",
    "We could write some quick code to classify that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine the cutoffs for Iris Setosa petal length\n",
    "setosa = df['Iris Flower'] == \"Setosa\"\n",
    "\n",
    "max_setosa = df['petal length (cm)'][setosa].max()\n",
    "print \"Setosa max petal length: {} cm\".format(max_setosa)\n",
    "\n",
    "# Find the minimum petal length for the other plants\n",
    "min_not_setosa = df['petal length (cm)'][-setosa].min()\n",
    "print \"Not Setosa min petal length: {} cm\".format(min_not_setosa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have this classification scheme, we can create a very simply model to identify the type of flower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "petal_length = df['petal length (cm)']\n",
    "#Incoming wall of text\n",
    "for flower in petal_length:\n",
    "    if flower <= 1.9:\n",
    "        print(\"Iris Setosa\")\n",
    "    else:\n",
    "        print(\"Iris Virginica or Iris Versicolour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "That was less than exciting. This was just a simple example of a **manually implemented dimension threshold**. Eventually, we will get some **machine learning** to do this for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we will never attain perfect separation between Iris Virginica and Iris Versicolour, since there is some degree of overlap between them.\n",
    "\n",
    "However, we can still try to implement another threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First we select non-Setosa flowers\n",
    "flowers = df[-setosa]\n",
    "\n",
    "# Create a boolean mask of Iris Virginica to test prediction against\n",
    "is_virginica = flowers['Iris Flower'] == 'Virginica'\n",
    "\n",
    "# Convert to plain matrix for this simple looping operation\n",
    "flowers = flowers.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to loop through each of the petal and sepal features in the data and test each value as a potential threshold. At the same time we will keep track of the threshold with the best prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_accuracy = [0, 0, 0]  # accuracy, feature, threshold\n",
    "# for each flower feature in the data (columns 1 - 4)\n",
    "# sepal length (cm) = 0 \t\n",
    "# sepal width (cm) = 1\t\n",
    "# petal length (cm)\t= 2\n",
    "# petal width (cm) = 3\n",
    "for feature in xrange(4):\n",
    "     \n",
    "    threshold = flowers[:,feature].copy()\n",
    "    threshold.sort()\n",
    "    \n",
    "    # Now test all these values as thresholds\n",
    "    for thresh in threshold:\n",
    "        prediction = flowers[:,feature] > thresh\n",
    "        accuracy = (prediction == is_virginica).mean()\n",
    "        if accuracy > best_accuracy[0]:\n",
    "            best_accuracy = [accuracy, feature, thresh]\n",
    "print best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we can see that we found our best flower classifying accuracy was 94% using petal width at 1.6 cm.\n",
    "\n",
    "Lets see how this looks on a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select non-Setosa flowers\n",
    "flowers = df[-setosa]\n",
    "ggplot(flowers, aes(x=\"petal width (cm)\", y=\"petal length (cm)\", \\\n",
    "                    color = \"Iris Flower\")) + \\\n",
    "geom_point() + \\\n",
    "geom_vline(xintercept = 1.6, color = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey! Not bad. **BUT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing / Training data and Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our previous model achieved 94% accuracy, however, this is likely over-estimated. We used the same data to both define the threshold, and then evaluate the model.\n",
    "\n",
    "What we should be doing is generalize the power of our model on new instances of data. In other words, we will define the threshold on a **training set** of data, and evaluate the model on the **test set** of data that the model did not see in training.\n",
    "\n",
    "It is therefore only appropriate to report training error, not testing error, when communicating your results.\n",
    "\n",
    "For now, we will split the data in half to achieve this, though more consideration should be taken later, in more complex models. Sometimes the models can be sensitive to how much data we include in either set. For example: sometimes too little data for testing could skew the result.\n",
    "\n",
    "To avoid this problem, it would be nice to somehow use all the data for both testing and training.\n",
    "\n",
    "This is where **cross-validation** comes in. There are many types of cross validation, but the most extreme case is **leave-one-out**. Under this framework, if we have 100 points of data in our training set, we:\n",
    "\n",
    "- remove *i* th element of the training set\n",
    "- train model using the training set\n",
    "- predict model with testing set, where testing = training - *i* th element\n",
    "- record the error\n",
    "- repeat until all *i* elements of training set have been omitted (one at a time)\n",
    "- sum error\n",
    "\n",
    "Generally, we don't use leave-one-out unless we need particularly high precision, as other techniques are sufficient for most cases. The biggest caveat of \"leave-one-out\" cross-validation is dramatic increases in computation speed, particularly as dataset become large.\n",
    "\n",
    "\n",
    "You can read up on the other types of cross validation <a href = \"http://en.wikipedia.org/wiki/Cross-validation_(statistics)\">here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a feel for testing and training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas, we can efficiently split the data into testing and training sets.\n",
    "\n",
    "Now let's modify our model definition from before and create a more formal function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model(input_data):\n",
    "    \n",
    "    # Determine the row index's for the testing set\n",
    "    test_rows = np.random.choice(input_data.index, size=50, replace = False)\n",
    "    # Use this as a mask on the full dataset\n",
    "\n",
    "    # Use .ix to specify array mask\n",
    "    testing_data = input_data.ix[test_rows]\n",
    "    training_data = input_data.drop(test_rows)\n",
    "    \n",
    "    # Create a boolean mask of Iris Virginica to test prediction against\n",
    "    is_virginica = testing_data['Iris Flower'] == 'Virginica'\n",
    "\n",
    "    # Convert to plain matrix for this simple looping operation\n",
    "    training_data = training_data.as_matrix()\n",
    "    \n",
    "    best_accuracy = [0, 0, 0]  # accuracy, feature, threshold\n",
    "    # for each flower feature in the data (columns 1 - 4)\n",
    "    # sepal length (cm) = 0 \t\n",
    "    # sepal width (cm) = 1\t\n",
    "    # petal length (cm)\t= 2\n",
    "    # petal width (cm) = 3\n",
    "    for feature in xrange(4):\n",
    "\n",
    "        threshold = training_data[:,feature].copy()\n",
    "        threshold.sort()\n",
    "\n",
    "        # Now test all these values as thresholds\n",
    "        for thresh in threshold:\n",
    "            prediction = training_data[:,feature] > thresh\n",
    "            accuracy = (prediction == is_virginica).mean()\n",
    "            \n",
    "            if accuracy > best_accuracy[0]:\n",
    "                best_accuracy = [accuracy, feature, thresh]\n",
    "    \n",
    "    return best_accuracy\n",
    "\n",
    "print \"Best model accuracy = {}\".format(model(flowers)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our results are much worse than before, but that's ok. We will be moving on to more sophisticated techniques soon.\n",
    "\n",
    "Before that, let's check how sensitive our model is to the random sampling of our training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_l = []\n",
    "i = 0\n",
    "\n",
    "while i < 1000:\n",
    "    results = model(flowers)[0]\n",
    "    results_l.append(results)\n",
    "    i+=1\n",
    "\n",
    "qplot(results_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 1000 runs we can start to get a pretty good picture of the potential variation. Generally, we will let our machine learning package handle this type of thing for us though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get into more complex classifiers. We will also be using a new agriculturally based dataset called <a href='http://archive.ics.uci.edu/ml/datasets/seeds#'>Seeds</a>, which consists of measurements of wheat seeds.\n",
    "\n",
    "Pandas can load the data right from a url. Note that we had to exclude come rows due to data errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt\"\n",
    "\n",
    "df = pd.read_csv(url, sep = \"\\t\", header=False, error_bad_lines=False,\n",
    "names = ['area','perim','compact','length','width','asymc','length_groove', 'wheat_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this dataset is a bit more complex than `iris`. We now have 7 features and three types of wheat: `Canadian`, `Koma`, and `Rosa`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of these 7 features, one of them, **compactness**, is not technically a new variable, but a function of two features, `perimeter` and `area`. It is common practise, and often very useful to derive new combined features like this. It usually termed **feature engineering**. \n",
    "\n",
    "The target for a good feature in any type of machine learning is that it is both varies with what matters and is invariate with what does not. Compactness in wheat varies with shape, and not size, which is a better predictor of wheat type. The best tool for creating good features is strong intuition and knowledge of the data. Generally, for most common sources of data, there are already a set of preferred and potential features generated by previous literature.\n",
    "\n",
    "**All in all, simpler is better.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nearest neighbour (KNN) is a supervised learning algorithm for classification or regression. One of the most common usages is for personalization tasks. To make an accurate personalized offer to a customer, you could use KNN to find similar customers and base your offer from their previous purchase behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "KNN is utilized when class labels are known for a dataset and you want to predict the class of a new data point. The predicted class will be based on the known classes NN. We are simply trying to find the class that is most similar to the new data point you are trying to predict.\n",
    "\n",
    "For example: what class should the green circle belong to? Blue or Red?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import Image\n",
    "Image(\"http://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/KnnClassification.svg/200px-KnnClassification.svg.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the right value of k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that  the correct value for `k` is very important. Generally, it is best to start out with an odd number, since this avoids situations where your classifier \"ties\" as a result of having the same number of votes for two or more classes. Like before in the IPython notebook for <a href = \"\">Curve Fitting (add link)</a>, we are vulnerable to <a href=\"http://en.wikipedia.org/wiki/Overfitting\">overfitting</a>. To remedy this we can examine a plot of accuracy over increasing `k`. The optimal `k` is not often the highest `k` values, but rather the `k` at which improvements in accuracy begin to slow down dramatically.\n",
    "\n",
    "Let's see what I mean here, and grab a dataset with many more values. Here we will use a few features of the wine ingredients to predict if it is high quality or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "df = pd.read_csv(\"https://s3.amazonaws.com/demo-datasets/wine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take a look at the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def best_k(df, features):\n",
    "    # Randomly sample 70% training data, 30% testing data\n",
    "    test_idx = np.random.uniform(0,1, len(df)) <= 0.3\n",
    "    train = df[test_idx==True]\n",
    "    test = df[test_idx==False]\n",
    "\n",
    "    # List of features we want to test\n",
    "    features = ['density', 'sulphates', 'residual_sugar']\n",
    "    results = []\n",
    "    for n in range(1,51,2):\n",
    "        clf = KNeighborsClassifier(n_neighbors=n)\n",
    "        clf.fit(train[features], train['high_quality'])\n",
    "        preds = clf.predict(test[features])\n",
    "        # If True = 1, if False = 0\n",
    "        accuracy = np.where(preds==test['high_quality'], 1, 0).sum() / float(len(test))\n",
    "\n",
    "        results.append([n, accuracy])\n",
    "\n",
    "    results = pd.DataFrame(results, columns = ['n', 'accuracy'])\n",
    "    \n",
    "    plot = ggplot(results, aes(\"n\", \"accuracy\"))+geom_line()\n",
    "    return [results, test, train, plot]\n",
    "\n",
    "# Features we want to use\n",
    "features = ['density', 'sulphates', 'residual_sugar']\n",
    "\n",
    "optimal_k_model = best_k(df, features)\n",
    "optimal_k_model[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from this plot, the `k` with the best accuracy can be found at around **37**, however, accuracy doesn't really improve much after `k = ~9`. Most of the trend is caught at this `k` level, and beyond that we risk overfitting. Again, there are more sophisticated ways of doing this, but that will be discussed later.\n",
    "\n",
    "In general, a larger `k` suppresses the effects of the noise, but makes the classification boundaries less distinct, which is really our actual goal.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance between points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, KNN classification utilizes the idea that each observation is represented by it's features in N-dimensional space. Therefore we can compute the distance between the observations (in several ways). The second most important parameter in KNN models is how you choose to calculate the distance between the points.\n",
    "\n",
    "The most common distance functions are `uniform`, which weights everything equally, and `distance`, which weights the points based on the inverse distance between them. There are many other ways to do this as well. \n",
    "\n",
    "Let's compare the results of all three of these types of weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def KNN(train_data, test_data, k):\n",
    "    results = []\n",
    "\n",
    "    for w in ['uniform','distance', lambda x: np.log(x)]:\n",
    "        # Run with 9 neighbors\n",
    "        clf = KNeighborsClassifier(k, weights=w)\n",
    "        w = str(w)\n",
    "        clf.fit(train_data[features], train_data['high_quality'])\n",
    "        prediction = clf.predict(test_data[features])\n",
    "        accuracy = np.where(prediction==test_data['high_quality'], 1, 0).sum() / float(len(test_data))\n",
    "\n",
    "        results.append([w, accuracy])\n",
    "\n",
    "    results = pd.DataFrame(results, columns = ['weight_method', 'accuracy'])\n",
    "\n",
    "    return results\n",
    "\n",
    "train = optimal_k_model[2]\n",
    "test = optimal_k_model[1]\n",
    "\n",
    "KNN(train, test, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty slick. Though ideally, we would select the weighting scheme based on some intuition about our data. Should there be more feature influence at shorter distances? When it doubt, inverse distance is a good place to start, because it helps avoid problems of \"majority voting\" where one class dominates the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed something about these above examples. We have been mixing up our units (this is bad) by summing up volumes, weights, densities and concentrations.\n",
    "\n",
    "Let's take a look at our data again to understand whats happening here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[features].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are computing distance between these features in 3D space, we can see that small changes in density and sulphates, will equate to large changes in residual sugar content. This, in essence, makes residual sugar seem more important if we are treating the units equally, since the numbers are simply larger.\n",
    "\n",
    "The solution is **standardization**, commonly referred to as **normalization** in statistics, whereby we adjust features on different scales to a single common scale. There are also various types of normalization, <a href=\"http://en.wikipedia.org/wiki/Normalization_(statistics)\">see here</a>.\n",
    "\n",
    "A common technique for normalizing **Z-score** (standard-score) values, which measures how far away from the mean a value is in terms of units of standard deviation. To do this we subtract the mean of each feature, then scale it by dividing it by their standard deviation. This can be implemented quite easily by hand, or also by using **`scale`** from `sklearns's` **`preprocessing`**  library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Let's standardize our data from before we put in into our functions\n",
    "# Remove color column because it is text and we arnt using it anyways.\n",
    "#del df['color']\n",
    "tmp = preprocessing.scale(df[features])\n",
    "# Re add the column names back\n",
    "df_norm = pd.DataFrame(tmp, columns = list(df[features].columns.values))\n",
    "# Re-join the \"High Quality\" feature we are trying to predict\n",
    "df_norm['high_quality'] = df['high_quality'] \n",
    "\n",
    "# Ignore some pesky warning about color not being an integer, thanks anyways pandas.\n",
    "import warnings\n",
    "warnings.simplefilter(action = \"ignore\", category = DeprecationWarning)\n",
    "\n",
    "df_norm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets repeat our KNN classification we did above with our newly standardized data and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find optimal k value\n",
    "optimal_k_model = best_k(df_norm, features)\n",
    "# Display the plot\n",
    "optimal_k_model[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our `k` is still pretty close to before standardization, where a `k = ~9` appears to capture most of the trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit KNN function with different weights\n",
    "# Extract the data from optimal_k_model\n",
    "train = optimal_k_model[2]\n",
    "test = optimal_k_model[1]\n",
    "KNN(train, test, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We can see that our model improves after standardization, this is because the distances are more accurately abstracted in 3D space.\n",
    "\n",
    "Lets go full circle now and predict if a **new** wine will be high quality or not using our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sulphates, Residual sugar, and density of two new unseen wine to pass to our model\n",
    "new_wine_features = [[0.66, 0.6, 0.92], [2.66, 2.1, 0.8]]\n",
    "\n",
    "# Going through the motions again for repitition, \n",
    "# normally we would just take our model computed from above\n",
    "\n",
    "train = optimal_k_model[2]\n",
    "test = optimal_k_model[1]\n",
    "\n",
    "clf = KNeighborsClassifier(9, \"distance\")\n",
    "clf.fit(train[features], train['high_quality'])\n",
    "\n",
    "print clf.get_params()\n",
    "print clf.predict(new_wine_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where 0 is not high quality and 1 is high quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"/users/ryankelly/desktop/custom_notebook.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "gist_id": "cbf1005e75cd04ad6921",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
